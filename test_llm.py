"""
Test script to verify Ollama LLM connection.
"""
from app.core.llm_client import test_llm_connection, get_llm

def main():
    print("ğŸ§ª Testing Ollama LLM connection...")
    
    if test_llm_connection():
        print("âœ… LLM connection successful!")
        
        # Try a simple travel-related question
        try:
            llm = get_llm()
            response = llm.invoke("What are 3 things to consider when packing for a trip?")
            print(f"\nğŸ“ Sample response:\n{response}")
        except Exception as e:
            print(f"âŒ Error getting sample response: {e}")
    else:
        print("âŒ LLM connection failed!")
        print("Make sure Ollama is running and llama3.1:8b model is available")

if __name__ == "__main__":
    main()